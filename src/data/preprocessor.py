import pandas as pd
import numpy as np
import logging
from typing import Any
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
import statsmodels.api as sm

class DataPreprocessor:
    """ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, config: Any):
        self.config = config
        self.logger = logging.getLogger('cluster_ml')
        self.is_fitted = False
        self.scalers = {}
        self.encoders = {}

    # ========================
    # fit_transform / transform
    # ========================
    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """í•™ìŠµ ë°ì´í„° ì „ì²˜ë¦¬ (fit + transform)"""
        self.logger.info("ğŸ”¨ ì „ì²˜ë¦¬ fit_transform ì‹œì‘")
        
        # ë°ì´í„° ê²€ì¦
        if df.empty:
            raise ValueError("ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
        self.logger.info(f"ì…ë ¥ ë°ì´í„° í¬ê¸°: {df.shape}")
        self.logger.info(f"ì…ë ¥ ë°ì´í„° ì»¬ëŸ¼: {df.columns.tolist()}")
        
        # prophet ì „ìš©    
        if 'Prophet' in self.config.training.models:
            df = df.rename(columns={
                self.config.data.target_column: 'y',
                'tm': 'ds'
            })
        
        # ê¸°ë³¸ ì „ì²˜ë¦¬
        df = self._base_preprocess(df)
        # df = df.dropna(subset=['heat_demand'])
        
        # íŒŒìƒ ë³€ìˆ˜ ì¶”ê°€
        df = self._create_features(df)
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§
        df = self._scale_numerical(df, is_training=True)
        
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        df = self._encode_categorical(df, is_training=True)
        
        # ì‹œê³„ì—´ ë³€ìˆ˜ ì¶”ê°€
        df = self._add_time_features(df)
        
        # tm ì»¬ëŸ¼ ì œê±° (í•„ìš”ì‹œ)
        df = df.drop(columns=['tm'])
        self.is_fitted = True
        self.logger.info(f"ì „ì²˜ë¦¬ ì™„ë£Œ: {df.shape}")
        return df

    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ (transform only)"""
        self.logger.info("ğŸ”¨ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ transform ì‹œì‘")
        if not self.is_fitted:
            raise ValueError("Preprocessorê°€ fitë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.logger.info(f"ì „ì²˜ë¦¬ transform ì‹œì‘: shape={df.shape}")
        # ê¸°ë³¸ ì „ì²˜ë¦¬
        df = self._base_preprocess(df)
        # df = df.dropna(subset=['heat_demand'])
        print(df.shape)
        # íŒŒìƒ ë³€ìˆ˜ ì¶”ê°€
        df = self._create_features(df)
        print(df.shape)
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§
        df = self._scale_numerical(df, is_training=True)
        print(df.shape)
        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
        df = self._encode_categorical(df, is_training=True)
        print(df.shape)
        # ì‹œê³„ì—´ ë³€ìˆ˜ ì¶”ê°€
        df = self._add_time_features(df)
        # tm ì»¬ëŸ¼ ì œê±° (í•„ìš”ì‹œ)
        df = df.drop(columns=['tm'])
        self.logger.info(f"ì „ì²˜ë¦¬ ë³€í™˜ ì™„ë£Œ: {df.shape}")
        return df

    # ========================
    # ê¸°ë³¸ ì „ì²˜ë¦¬
    # ========================
    def _base_preprocess(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê¸°ë³¸ ì „ì²˜ë¦¬: ë‚ ì§œ ë³€í™˜, ë”ë¯¸ ìƒì„±, ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°"""
        self.logger.info("ğŸ”¨ ê¸°ë³¸ ì „ì²˜ë¦¬")
        df = df.copy()
        
        # ë°ì´íŠ¸ íƒ€ì„ ë³€ê²½ & ì›” ì¶”ê°€
        df['tm'] = pd.to_datetime(df['tm'].astype(str), format="%Y%m%d%H")
        df['month'] = df['tm'].dt.month
        
        # 263069ê°œì˜ ê²°ì¸¡ì¹˜ -> naë¡œ ëŒ€ì²´
        df = df.replace(-99, np.nan)

        # í’í–¥ -9.9 ê°’ì„ NaNìœ¼ë¡œ ë³€ê²½
        df['wd'] = df['wd'].replace(-9.9, np.nan)
        
        # branch_dummies = pd.get_dummies(df['branch_id'], prefix='branch_id', drop_first=True)
        # df = pd.concat([df.drop('branch_id', axis=1), branch_dummies], axis=1)
        # df = df.drop(columns=['tm', 'tm_dt'])
        return df

    # ========================
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    # ========================
    def _handle_missing_values(self, df: pd.DataFrame, is_training: bool = True) -> pd.DataFrame:
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬: íŒ¨í„´ë³„ si ì±„ì›€, ì¥ë‹¨ê¸° ê²°ì¸¡ì¹˜ ë³´ê°„"""
        self.logger.info("ğŸ”¨ ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
        # ... (íŒ¨í„´ ê·¸ë£¹ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë¡œì§ ë™ì¼)
        return df

    # ========================
    # íŒŒìƒ ë³€ìˆ˜ ìƒì„±
    # ========================
    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """íŒŒìƒ ë³€ìˆ˜ ìƒì„±: ì‹œê°„, ê³„ì ˆ, í’í–¥/í’ì†, ì´ìŠ¬ì  ë“±"""
        self.logger.info("ğŸ”¨ íŒŒìƒ ë³€ìˆ˜ ìƒì„±")
        
        if 'Prophet' in self.config.training.models:
            # Prophet ì‚¬ìš© ì‹œ íŠ¹ì§• ìƒì„± ìƒëµ
            return df[['ds', 'y', 'branch_id']] 
        
        else:
            df['year'] = df['tm'].dt.year
            df['day'] = df['tm'].dt.day
            df['hour'] = df['tm'].dt.hour

            # # ì‹œê°„ëŒ€ êµ¬ë¶„
            # df['time_period'] = pd.cut(df['hour'], 
            #                         bins=[0, 6, 12, 18, 24], 
            #                         labels=['night', 'morning', 'afternoon', 'evening'])
                
            # ìš”ì¼ ì¶”ê°€ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            df['weekday'] = df['day'] % 7
                
            # ê³„ì ˆ êµ¬ë¶„
            df['season'] = df['month'].map(lambda x: 
                'spring' if x in [3,4,5] else
                'summer' if x in [6,7,8] else  
                'autumn' if x in [9,10,11] else 'winter')
            
            #í’í–¥ê·¸ë£¹
            self.logger.info("ğŸ”¨ í’í–¥")
            df['wd_group'] = df['wd'].apply(self._categorize_wind_direction)

            #í’ì†ê·¸ë£¹
            self.logger.info("ğŸ”¨ í’ì†")
            df['ws_group'] = df['ws'].apply(self._categorize_ws)

            #ì´ìŠ¬ì 
            self.logger.info("ğŸ”¨ ì´ìŠ¬ì  ê³„ì‚°")
            df['dew_point'] = df.apply(lambda row: self._dew_point(row['ta'], row['hm']), axis=1)
            
            # lag ë³€ìˆ˜ ì¶”ê°€
            df = self._add_lag_features(df, lag=1)

            #ì´ë™í‰ê· 
            target_cols = ['wd', 'ws', 'rn_hr1', 'rn_day']
            df = self._add_moving_averages(df, target_cols, window_size=3)
            
            # #trend ,ê³„ì ˆì„±ë³€ìˆ˜
            # daily_avg = (
            # df.copy()
            # .assign(date=lambda x: x['tm'].dt.date)
            # .groupby('date')['heat_demand']
            # .mean()
            # )

            # # STL ë¶„í•´
            # result = sm.tsa.seasonal_decompose(daily_avg, model='additive', period=365)
            # df['trend'] = result.trend
            # df['seasonal'] =result.seasonal
            # df['residual'] = result.resid
            
        return df

    # ========================
    # ë²”ì£¼í˜• ì¸ì½”ë”©
    # ========================
    def _encode_categorical(self, df: pd.DataFrame, is_training: bool = True) -> pd.DataFrame:
        """ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©"""
        self.logger.info("ğŸ”¨ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©")
        categorical_cols = df.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            if col == self.config.data.target_column:
                continue
            if is_training:
                encoder = LabelEncoder()
                df[col] = encoder.fit_transform(df[col].astype(str))
                self.encoders[col] = encoder
            else:
                if col in self.encoders:
                    encoder = self.encoders[col]
                    df[col] = df[col].map(lambda x: encoder.transform([str(x)])[0] 
                                          if str(x) in encoder.classes_ else -1)
        return df

    # ========================
    # ìˆ˜ì¹˜í˜• ìŠ¤ì¼€ì¼ë§
    # ========================
    def _scale_numerical(self, df: pd.DataFrame, is_training: bool = True) -> pd.DataFrame:
        """ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§"""
        self.logger.info("ğŸ”¨ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§")
        numerical_cols = df.select_dtypes(include=[np.number]).columns
        # exclude_cols = ['id', 'cluster_id', 'heat_demand', 'log_heat_demand']
        # scale_cols = [col for col in numerical_cols if col not in exclude_cols]
        # if is_training:
        #     scaler = StandardScaler()
        #     df[scale_cols] = scaler.fit_transform(df[scale_cols])
        #     self.scalers['numerical'] = scaler
        # else:
        #     if 'numerical' in self.scalers:
        #         scaler = self.scalers['numerical']
        #         df[scale_cols] = scaler.transform(df[scale_cols])
        return df

    # ========================
    # ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ (í“¨ë¦¬ì—/ìˆœí™˜)
    # ========================
    def _add_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€: í“¨ë¦¬ì—, ìˆœí™˜(sin/cos) ë³€í™˜ ë“±"""
        self.logger.info("ğŸ”¨ ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€")
        df_copy = df.copy()

        df_copy = df_copy.set_index('tm')              # tmì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
        
        # ì¼ í‰ê·  ì‹œê³„ì—´ (STLìš©)
        daily_avg = df_copy['ta'].resample('D').mean()

        df_copy = df_copy.reset_index()  # tmì„ ë‹¤ì‹œ ì¹¼ëŸ¼ìœ¼ë¡œ

        # STL ë¶„í•´
        # period = 30  # ì›”ê°„ ê³„ì ˆì„± ê°€ì •

        # result = sm.tsa.seasonal_decompose(daily_avg, model='additive', period=period)

        # # STL ë¶„í•´ í›„: NaN í¬í•¨ëœ resid
        # resid = result.resid

        # # ì„ í˜• ë³´ê°„ + ì•ë’¤ ê²°ì¸¡ ë³´ì™„
        # resid_filled = resid.interpolate(method='time').ffill().bfill()  # ì‹œê°„ê¸°ë°˜ ë³´ê°„ + ì•ë’¤ ê²°ì¸¡ ì²˜ë¦¬

        # df = self._process_fft_filtering(resid_filled, df)

        """ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€"""
        # ì‹œê°„ ê¸°ë°˜ ìˆœí™˜ íŠ¹ì„± (sin, cos ë³€í™˜)
        df['hour_of_week'] = df['tm'].dt.dayofweek * 24 + df['hour']
        df['day_of_month'] = df['tm'].dt.day

        # í•˜ë£¨ ë‹¨ìœ„ 
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        # ì¼ì£¼ì¼ ë‹¨ìœ„
        df['weekhour_sin'] = np.sin(2 * np.pi * df['hour_of_week'] / 168)
        df['weekhour_cos'] = np.cos(2 * np.pi * df['hour_of_week'] / 168)
        # ì›” ë‹¨ìœ„ 
        df['month_sin'] = np.sin(2 * np.pi * df['day_of_month'] / 30)
        df['month_cos'] = np.cos(2 * np.pi * df['day_of_month'] / 30)

        return df

    # ========================
    # ê¸°íƒ€ ìœ í‹¸ í•¨ìˆ˜
    # ========================
    def _categorize_wind_direction(self, degree):
        """í’í–¥ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜"""
        
        if 45 <= degree < 135:
            return 'E'
        elif 135 <= degree < 225:
            return 'S'
        elif 225 <= degree < 315:
            return 'W'
        else:
            return 'N'

    def _categorize_ws(self, ws):
        """í’ì†ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜"""
        if ws < 1:
            return 'ì •ì§€'
        elif ws < 4:
            return 'ì•½í’'
        elif ws < 9:
            return 'ì¤‘í’'
        else:
            return 'ê°•í’'

    def _dew_point(self, temp, humidity):
        """ì´ìŠ¬ì  ê³„ì‚°"""
        a, b = 17.27, 237.7
        alpha = ((a * temp) / (b + temp)) + np.log(humidity / 100)
        return (b * alpha) / (a - alpha)

    def _add_lag_features(self, df, lag=1)-> pd.DataFrame:
        '''ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— lag ë³€ìˆ˜ ì¶”ê°€'''    
        # ì‚¬ìš©í•  ë³€ìˆ˜ì™€ lag ì‹œê¸° ì •ì˜
        target_vars = ['ta', 'hm', 'si', 'ta_chi']
        lags = [1, 2, 24, 25]

        # ê° ë³€ìˆ˜ë³„, ê° lagë³„ë¡œ shift ì ìš©
        for var in target_vars:
            for lag in lags:
                df[f'{var}_lag_{lag}'] = df.groupby('branch_id')[var].shift(lag)

        return df
    
    def _add_moving_averages(self, df, target_cols, window_size=3) -> pd.DataFrame:
        '''branch_idë³„ ì´ë™í‰ê·  ì¶”ê°€'''

        if 'branch_id' not in df.columns or 'tm' not in df.columns:
         raise ValueError("âš ï¸ 'branch_id' ë˜ëŠ” 'tm' ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
        #   ì‹œê°„ ì •ë ¬ (branchë³„ rollingì„ ì ìš©í•˜ë ¤ë©´ ë°˜ë“œì‹œ í•„ìš”)
        df = df.sort_values(['branch_id', 'tm'])

        for col in target_cols:
            if col in df.columns:
                df[f'{col}_ma'] = (
                 df.groupby('branch_id')[col]
                      .transform(lambda x: x.rolling(window=window_size, min_periods=window_size).mean())
                )
                print(f"âœ… {col} ì´ë™í‰ê·  ê³„ì‚° ì™„ë£Œ")
            else:
                print(f"âŒ {col} ì»¬ëŸ¼ ì—†ìŒ")
        return df