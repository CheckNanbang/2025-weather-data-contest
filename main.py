import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import yaml
import logging
from typing import Dict, List, Tuple, Any

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from src.data.data_loader import DataLoader
from src.data.preprocessor import DataPreprocessor
from src.models.model_factory import ModelFactory
from src.training.trainer import ClusterTrainer
from src.evaluation.evaluator import ModelEvaluator
from src.utils.logger import setup_logging
from src.utils.config import Config
from src.utils.file_manager import FileManager

class ClusterMLPipeline:
    """í´ëŸ¬ìŠ¤í„°ë³„ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        self.config = Config(config_path)
        self.logger = setup_logging(self.config)
        self.file_manager = FileManager(self.config)
        self.experiment_id = self._generate_experiment_id()
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.cluster_results = {}
        self.cluster_metrics = {}
        
    def _generate_experiment_id(self) -> str:
        """ì‹¤í—˜ ID ìƒì„±"""
        timestamp = datetime.now().strftime("%m%d_%H%M%S")
        return f"{self.config.experiment.name}_{timestamp}"
    
    def run(self, selected_clusters: List[int] = None, predict: bool = False) -> Dict[str, Any]:
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        self.logger.info(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {self.experiment_id}")
        try:
            train_df, test_df, submission_df = self._load_data()
            train_df, test_df = self._add_cluster_ids(train_df, test_df)
            if selected_clusters is None:
                selected_clusters = list(self.config.cluster.mapping.keys())
            self._train_clusters(train_df, test_df, selected_clusters, predict=predict)
            submission_file = None
            if predict:
                submission_file = self._generate_submission(submission_df)
            self._save_results_and_report()
            self.logger.info("âœ… ì‹¤í—˜ ì™„ë£Œ!")
            return {
                'experiment_id': self.experiment_id,
                'cluster_metrics': self.cluster_metrics,
                'submission_file': submission_file
            }
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
    
    def _load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„° ë¡œë”©"""
        self.logger.info("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        data_loader = DataLoader(self.config)
        return data_loader.load()
    
    def _add_cluster_ids(self, train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """í´ëŸ¬ìŠ¤í„° ID ì¶”ê°€"""
        self.logger.info("ğŸ·ï¸ í´ëŸ¬ìŠ¤í„° ID ë§¤í•‘ ì¤‘...")
        
        # branch_id â†’ cluster_id ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        branch_to_cluster = {}
        for cluster_id, branches in self.config.cluster.mapping.items():
            for branch in branches:
                branch_to_cluster[branch] = cluster_id
        
        train_df['cluster_id'] = train_df['branch_id'].map(branch_to_cluster)
        test_df['cluster_id'] = test_df['branch_id'].map(branch_to_cluster)
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ë°ì´í„° í™•ì¸
        unmapped_train = train_df[train_df['cluster_id'].isna()]
        unmapped_test = test_df[test_df['cluster_id'].isna()]
        
        if len(unmapped_train) > 0 or len(unmapped_test) > 0:
            self.logger.warning(f"ë§¤í•‘ë˜ì§€ ì•Šì€ ë°ì´í„°: train {len(unmapped_train)}, test {len(unmapped_test)}")
        
        return train_df, test_df
    
    def _train_clusters(self, train_df: pd.DataFrame, test_df: pd.DataFrame, selected_clusters: List[int], predict=False) -> None:
        self.logger.info(f"ğŸ¯ ì„ íƒëœ í´ëŸ¬ìŠ¤í„°: {selected_clusters}")
        
        # ì „ì²´ valid ë°ì´í„° ëª¨ìœ¼ê¸°ìš© ë¦¬ìŠ¤íŠ¸ â† ë°˜ë“œì‹œ ì¶”ê°€!
        all_valid_true = []
        all_valid_pred = []
        
        for cluster_id in selected_clusters:
            self.logger.info(f"{'='*20} í´ëŸ¬ìŠ¤í„° {cluster_id} ì²˜ë¦¬ ì‹œì‘ {'='*20}")
            train_cluster = train_df[train_df['cluster_id'] == cluster_id].copy()
            test_cluster = test_df[test_df['cluster_id'] == cluster_id].copy()
            if len(train_cluster) == 0:
                self.logger.warning(f"í´ëŸ¬ìŠ¤í„° {cluster_id}ì— í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            cluster_trainer = ClusterTrainer(self.config, cluster_id, self.experiment_id)
            result = cluster_trainer.train_and_predict(train_cluster, test_cluster)
            
            # predictionsê°€ Noneì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì²´í¬í•´ì„œ ì €ì¥
            if result['predictions'] is not None:
                self.cluster_results[cluster_id] = result['predictions']
            self.cluster_metrics[cluster_id] = result['metrics']
            self.logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_id} ì™„ë£Œ")

            # (1) í´ëŸ¬ìŠ¤í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸(RMSE ê¸°ì¤€) validation ì˜ˆì¸¡ê°’ë§Œ ì§‘ê³„
            best_model = None
            best_rmse = float('inf')
            best_metrics = None
            for model_name, metrics in result['metrics'].items():
                rmse = metrics.get("RMSE")
                if rmse is not None and rmse < best_rmse:
                    best_rmse = rmse
                    best_model = model_name
                    best_metrics = metrics
            if best_metrics is not None:
                y_valid_true = best_metrics.get("y_valid_true")
                y_valid_pred = best_metrics.get("y_valid_pred")
                if y_valid_true is not None and y_valid_pred is not None:
                    all_valid_true.append(y_valid_true)
                    all_valid_pred.append(y_valid_pred)

        # (2) ì „ì²´ í‰ê°€ì§€í‘œ ê³„ì‚° ë° ì¶œë ¥
        if all_valid_true and all_valid_pred:
            import numpy as np
            y_true_all = np.concatenate(all_valid_true)
            y_pred_all = np.concatenate(all_valid_pred)
            evaluator = ModelEvaluator(self.config)
            global_metrics = evaluator.evaluate(y_true_all, y_pred_all)
            self.logger.info("====== ì „ì²´(ê¸€ë¡œë²Œ) ê²€ì¦ í‰ê°€ì§€í‘œ (í´ëŸ¬ìŠ¤í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ê¸°ì¤€) ======")
            for metric, value in global_metrics.items():
                if value is not None:
                    self.logger.info(f"  {metric}: {value:.4f}")


    
    def _generate_submission(self, submission_df: pd.DataFrame) -> str:
        """ì œì¶œ íŒŒì¼ ìƒì„±"""
        if not self.cluster_results:
            self.logger.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ì–´ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        self.logger.info("ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ê²°ê³¼ í†µí•©
        all_predictions = []
        for cluster_id, predictions in self.cluster_results.items():
            all_predictions.append(predictions)
        
        final_predictions = pd.concat(all_predictions, ignore_index=True)
        final_predictions = final_predictions.sort_values('id')
        
        # ì œì¶œìš© ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
        submission_df = submission_df.drop(columns=[self.config.data.target_column], errors="ignore")
        submission_df = submission_df.merge(final_predictions[['id', self.config.data.target_column]], 
                                          on='id', how='left')
        
        # íŒŒì¼ ì €ì¥
        submission_file = self.file_manager.save_submission(submission_df, self.experiment_id)
        self.logger.info(f"ğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥: {submission_file}")
        
        return submission_file
    
    def _save_results_and_report(self) -> None:
        """ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„±"""
        self.logger.info("ğŸ’¾ ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        # ë©”íŠ¸ë¦­ ì €ì¥
        self.file_manager.save_metrics(self.cluster_metrics, self.experiment_id)
        
        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        evaluator = ModelEvaluator(self.config)
        evaluator.generate_report(self.cluster_metrics, self.experiment_id)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="í´ëŸ¬ìŠ¤í„°ë³„ ML íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--config", type=str, default="config/config.yaml", 
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--clusters", nargs="*", type=int, 
                       help="í•™ìŠµí•  í´ëŸ¬ìŠ¤í„° ID (ê¸°ë³¸ê°’: ëª¨ë“  í´ëŸ¬ìŠ¤í„°)")
    parser.add_argument("--predict", action="store_true", help="ìµœì¢… ì˜ˆì¸¡(ì œì¶œ)ê¹Œì§€ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = ClusterMLPipeline(args.config)
    results = pipeline.run(selected_clusters=args.clusters, predict=args.predict)
    
    print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ! ID: {results['experiment_id']}")

if __name__ == "__main__":
    main()