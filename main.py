import os
import sys
import pandas as pd
from datetime import datetime
import optuna

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from dataloader.data_loader import data_loader
from utils.data_split import data_split
from utils.load_params import load_params
from models.train_model import train_model
from utils.evaluation import evaluate
from utils.cli_utils import parse_args, parse_params
from utils.log_utils import setup_logger, save_metrics_to_csv
from utils.train_utils import objective, plot_results

# í´ëŸ¬ìŠ¤í„° ë§¤í•‘ ì •ì˜ (branch_id â†’ cluster_id)
CLUSTER_MAP = {
    0: ['E', 'K', 'R', 'S'],
    1: ['F', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q'],
    2: ['A', 'B', 'C', 'D', 'G', 'H'],
}

def add_cluster_id(df):
    branch_to_cluster = {}
    for cluster_id, branches in CLUSTER_MAP.items():
        for b in branches:
            branch_to_cluster[b] = cluster_id
    df['cluster_id'] = df['branch_id'].map(branch_to_cluster)
    return df

class Tee:
    def __init__(self, *files):
        self.files = files
    def write(self, obj):
        for f in self.files:
            f.write(obj)
            f.flush()
    def flush(self):
        for f in self.files:
            f.flush()

def main():
    args = parse_args()
    now = datetime.now()
    date_code = now.strftime("%m%d%H%M%S")
    save_name = f"{args.model}_{args.dataset}_{args.split_type}_{date_code}.csv"

    log_filename = f"{args.model}_{date_code}.log"
    log_path = os.path.join("logs", log_filename)
    os.makedirs("logs", exist_ok=True)
    logfile = open(log_path, "a", encoding="utf-8-sig")
    sys.stdout = Tee(sys.stdout, logfile)
    sys.stderr = Tee(sys.stderr, logfile)
    logger = setup_logger(log_filename)
    logger.info(f"í”„ë¡œê·¸ë¨ ì‹œì‘: {args.model} ëª¨ë¸, {args.dataset} ë°ì´í„°ì…‹, {args.split_type} ë¶„í•  ë°©ì‹")

    try:
        # ë°ì´í„° ë¡œë”©
        logger.info("ë°ì´í„° ë¡œë”© ì¤‘...")
        train_df, test_df, submission_df, target_column = data_loader(args.dataset)
        print(train_df.columns)

        # branch_id â†’ cluster_id ë§¤í•‘
        train_df = add_cluster_id(train_df)
        test_df = add_cluster_id(test_df)

        # ì„ íƒì  í´ëŸ¬ìŠ¤í„° í•™ìŠµ (ì˜ˆ: --clusters 1 2)
        selected_clusters = getattr(args, 'clusters', list(CLUSTER_MAP.keys()))

        cluster_results = []
        cluster_metrics = []

        for cluster_id in selected_clusters:
            logger.info(f"===== [í´ëŸ¬ìŠ¤í„° {cluster_id}] ì²˜ë¦¬ ì‹œì‘ =====")
            train_c = train_df[train_df['cluster_id'] == cluster_id].copy()
            test_c = test_df[test_df['cluster_id'] == cluster_id].copy()

            # ë°ì´í„° ë¶„í• 
            x_train, x_valid, y_train, y_valid = data_split(args.split_type, train_c, target_column)
            X_test = test_c.copy()

            for df in [x_train, x_valid, X_test]:
                if 'branch_id' in df.columns:
                    df['branch_id'] = df['branch_id'].astype('category')

            # íŒŒë¼ë¯¸í„° ë¡œë“œ ë° ë³‘í•©
            default_params = load_params(args.model)
            user_params = parse_params(args.params)
            params = {**default_params, **user_params}
            
            params['enable_categorical'] = True

            logger.info("ğŸ”§ ìµœì¢… ì‚¬ìš© íŒŒë¼ë¯¸í„°:")
            for k, v in params.items():
                logger.info(f"  - {k}: {v}")

            # Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
            if args.tune:
                logger.info(f"Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘ (ì‹œë„ íšŸìˆ˜: {args.n_trials})")
                study = optuna.create_study(direction="minimize")
                study.optimize(
                    lambda trial: objective(trial, args.model, x_train, y_train, x_valid, y_valid),
                    n_trials=args.n_trials
                )
                logger.info("ğŸ¯ ìµœì  íŒŒë¼ë¯¸í„°:")
                for k, v in study.best_trial.params.items():
                    logger.info(f"  - {k}: {v}")
                params.update(study.best_trial.params)

            # ëª¨ë¸ í•™ìŠµ
            logger.info("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            model = train_model(args.model, params, x_train, y_train, x_valid, y_valid)
            logger.info("âœ… í•™ìŠµ ì™„ë£Œ!")

            # ê²€ì¦ ì˜ˆì¸¡ ë° í‰ê°€
            y_valid_pred = model.predict(x_valid)
            metrics = evaluate(y_valid, y_valid_pred)
            metrics['cluster'] = cluster_id
            cluster_metrics.append(metrics)

            logger.info("ğŸ“Š ê²€ì¦ ì„±ëŠ¥ ì§€í‘œ:")
            for k, v in metrics.items():
                if k == 'cluster': continue
                if v is not None:
                    result = f"{k}: {v:.4f}"
                else:
                    result = f"{k}: ê³„ì‚° ë¶ˆê°€"
                logger.info(result)

            # ê²°ê³¼ ì‹œê°í™”
            if args.plot:
                logger.info("ğŸ“ˆ ê²°ê³¼ ì‹œê°í™” ì¤‘...")
                plot_results(model, x_valid, y_valid, y_valid_pred)

            # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥
            if args.submit:
                logger.info("ğŸ“ ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")

                # ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ
                x_total = pd.concat([x_train, x_valid], axis=0)
                y_total = pd.concat([y_train, y_valid], axis=0)
                logger.info(f"ì „ì²´ ë°ì´í„° í¬ê¸°: {len(x_total)} ìƒ˜í”Œ")
                final_model = train_model(args.model, params, x_total, y_total)

                X_test = X_test.drop(columns=[target_column], errors="ignore")
                test_pred = final_model.predict(X_test)
                X_test['heat_demand'] = test_pred
                cluster_results.append(X_test[['id', 'heat_demand']])  # id ì»¬ëŸ¼ëª…ì€ ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ

        # ê²°ê³¼ í†µí•© ë° ì œì¶œ íŒŒì¼ ìƒì„±
        if args.submit and cluster_results:
            logger.info("í´ëŸ¬ìŠ¤í„°ë³„ ê²°ê³¼ í†µí•© ë° ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
            final_submission = pd.concat(cluster_results).sort_values('id')
            submission_df = submission_df.drop(columns=['heat_demand'], errors="ignore")
            submission_df = submission_df.merge(final_submission, on='id', how='left')
            submission_df.to_csv(save_name, index=False, encoding='utf-8-sig')
            logger.info(f"ğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_name}")

        # í´ëŸ¬ìŠ¤í„°ë³„ ì„±ëŠ¥ ì €ì¥
        save_metrics_to_csv(date_code, args.model, cluster_metrics)

        logger.info("í”„ë¡œê·¸ë¨ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")

    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise

if __name__ == "__main__":
    main()
