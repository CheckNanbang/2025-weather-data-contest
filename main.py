import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import yaml
import logging
from typing import Dict, List, Tuple, Any

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from src.data.data_loader import DataLoader
from src.data.preprocessor import DataPreprocessor
from src.models.model_factory import ModelFactory
from src.training.trainer import ClusterTrainer
from src.evaluation.evaluator import ModelEvaluator
from src.utils.logger import setup_logging
from src.utils.config import Config
from src.utils.file_manager import FileManager

class ClusterMLPipeline:
    """í´ëŸ¬ìŠ¤í„°ë³„ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self, config_path: str = "config/config.yaml"):
        # ì„¤ì • ë° ê°ì¢… ìœ í‹¸ ê°ì²´ ì´ˆê¸°í™”
        self.config = Config(config_path)
        self.logger = setup_logging(self.config)
        self.file_manager = FileManager(self.config)
        self.experiment_id = self._generate_experiment_id()
        # í´ëŸ¬ìŠ¤í„°ë³„ ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.cluster_results = {}
        self.cluster_metrics = {}

    def _generate_experiment_id(self) -> str:
        """ì‹¤í—˜ ID ìƒì„± (ì‹¤í—˜ëª…_ë‚ ì§œì‹œê°„)"""
        timestamp = datetime.now().strftime("%m%d_%H%M%S")
        return f"{self.config.experiment.name}_{timestamp}"

    def run(self, selected_clusters: List[int] = None, predict: bool = False) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜"""
        self.logger.info(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {self.experiment_id}")
        try:
            # ë°ì´í„° ë¡œë”©
            train_df, test_df, submission_df = self._load_data()
            # branch_id â†’ cluster_id ë§¤í•‘
            train_df, test_df = self._add_cluster_ids(train_df, test_df)
            # í´ëŸ¬ìŠ¤í„° ë¯¸ì§€ì • ì‹œ ì „ì²´ ì‚¬ìš©
            if selected_clusters is None:
                selected_clusters = list(self.config.cluster.mapping.keys())
            # í´ëŸ¬ìŠ¤í„°ë³„ í•™ìŠµ/ì˜ˆì¸¡
            self._train_clusters(train_df, test_df, selected_clusters, predict=predict)
            submission_file = None
            # ì˜ˆì¸¡ ëª¨ë“œë©´ ì œì¶œ íŒŒì¼ ìƒì„±
            if predict:
                submission_file = self._generate_submission(submission_df)
            # ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„±
            self._save_results_and_report()
            self.logger.info("âœ… ì‹¤í—˜ ì™„ë£Œ!")
            return {
                'experiment_id': self.experiment_id,
                'cluster_metrics': self.cluster_metrics,
                'submission_file': submission_file
            }
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise

    def _load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„° ë¡œë”© í•¨ìˆ˜"""
        self.logger.info("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        data_loader = DataLoader(self.config)
        return data_loader.load()

    def _add_cluster_ids(self, train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """branch_idë¥¼ cluster_idë¡œ ë§¤í•‘í•˜ì—¬ ì»¬ëŸ¼ ì¶”ê°€"""
        self.logger.info("ğŸ·ï¸ í´ëŸ¬ìŠ¤í„° ID ë§¤í•‘ ì¤‘...")
        # branch_id â†’ cluster_id ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        branch_to_cluster = {}
        for cluster_id, branches in self.config.cluster.mapping.items():
            for branch in branches:
                branch_to_cluster[branch] = cluster_id
        # ë§¤í•‘ ì ìš©
        train_df['cluster_id'] = train_df['branch_id'].map(branch_to_cluster)
        test_df['cluster_id'] = test_df['branch_id'].map(branch_to_cluster)
        
        try:
            train_df['month'] = pd.to_datetime(train_df['tm'], errors='coerce', format='%Y%m%d%H').dt.month
            test_df['month'] = pd.to_datetime(test_df['tm'], errors='coerce', format='%Y%m%d%H').dt.month
        except KeyError as e:
            self.logger.error("ë‚ ì§œ(date) ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            raise   
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ë°ì´í„° í™•ì¸
        unmapped_train = train_df[train_df['cluster_id'].isna()]
        unmapped_test = test_df[test_df['cluster_id'].isna()]
        if len(unmapped_train) > 0 or len(unmapped_test) > 0:
            self.logger.warning(f"ë§¤í•‘ë˜ì§€ ì•Šì€ ë°ì´í„°: train {len(unmapped_train)}, test {len(unmapped_test)}")
        return train_df, test_df

    def _train_clusters(
        self,
        train_df: pd.DataFrame,
        test_df: pd.DataFrame,
        selected_clusters: List[int],
        predict=False
    ) -> None:
        self.logger.info(f"ğŸ¯ ì„ íƒëœ í´ëŸ¬ìŠ¤í„°: {selected_clusters}")

        all_valid_true = []
        all_valid_pred = []

        for cluster_id in selected_clusters:
            self.logger.info(f"{'='*20} í´ëŸ¬ìŠ¤í„° {cluster_id} ì²˜ë¦¬ ì‹œì‘ {'='*20}")

            # cluster2ë§Œ ì›”ë³„ ë¶„ê¸° ì²˜ë¦¬
            if (
                str(cluster_id) == "2"  # int/str í˜¼ìš© ëŒ€ë¹„
                and hasattr(self, "cluster2_mode")
                and self.cluster2_mode == "split"
            ):
                # 6~9ì›”: summer, ë‚˜ë¨¸ì§€: rest
                
                print(train_df.head())
                # í´ëŸ¬ìŠ¤í„° 2ì˜ ì›”ë³„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
                print(train_df[train_df['cluster_id']==2]['month'].value_counts().sort_index())

                print(train_df['month'].dtype)
                # pd.NA â†’ NaN ë³€í™˜ í›„ ì •ìˆ˜í˜•ìœ¼ë¡œ ìºìŠ¤íŒ…
                train_df['month'] = train_df['month'].astype(float).fillna(-1).astype(int)
                test_df['month'] = test_df['month'].astype(float).fillna(-1).astype(int)
                
                summer_mask = train_df['month'].isin([6, 7, 8, 9])
                train_summer = train_df[(train_df['cluster_id'] == 2) & summer_mask].copy()
                train_rest = train_df[(train_df['cluster_id'] == 2) & (~summer_mask)].copy()
                test_summer = test_df[(test_df['cluster_id'] == 2) & test_df['month'].isin([6,7,8,9])].copy()
                test_rest = test_df[(test_df['cluster_id'] == 2) & (~test_df['month'].isin([6,7,8,9]))].copy()

                print(f"í´ëŸ¬ìŠ¤í„° 2: ì—¬ë¦„ {len(train_summer)}ê°œ, ë‚˜ë¨¸ì§€ {len(train_rest)}ê°œ")
                print(train_summer.head())
                print(test_summer.head())
                
                
                # summer í•™ìŠµ
                if len(train_summer) > 0:
                    self.logger.info(f"í´ëŸ¬ìŠ¤í„° 2_summer (6~9ì›”) í•™ìŠµ")
                    cluster_trainer = ClusterTrainer(self.config, "2_summer", self.experiment_id)
                    result = cluster_trainer.train_and_predict(train_summer, test_summer, predict=predict)
                    if result.get('predictions') is not None:
                        self.cluster_results["2_summer"] = result['predictions']
                    self.cluster_metrics["2_summer"] = result['metrics']
                    # ê²€ì¦ ì§‘ê³„
                    best_model = None
                    best_rmse = float('inf')
                    best_metrics = None
                    for model_name, metrics in result['metrics'].items():
                        rmse = metrics.get("RMSE")
                        if rmse is not None and rmse < best_rmse:
                            best_rmse = rmse
                            best_model = model_name
                            best_metrics = metrics
                    if best_metrics is not None:
                        y_valid_true = best_metrics.get("y_valid_true")
                        y_valid_pred = best_metrics.get("y_valid_pred")
                        if y_valid_true is not None and y_valid_pred is not None:
                            all_valid_true.append(y_valid_true)
                            all_valid_pred.append(y_valid_pred)

                # rest í•™ìŠµ
                if len(train_rest) > 0:
                    self.logger.info(f"í´ëŸ¬ìŠ¤í„° 2_rest (1~5,10~12ì›”) í•™ìŠµ")
                    cluster_trainer = ClusterTrainer(self.config, "2_rest", self.experiment_id)
                    result = cluster_trainer.train_and_predict(train_rest, test_rest, predict=predict)
                    if result.get('predictions') is not None:
                        self.cluster_results["2_rest"] = result['predictions']
                    self.cluster_metrics["2_rest"] = result['metrics']
                    # ê²€ì¦ ì§‘ê³„
                    best_model = None
                    best_rmse = float('inf')
                    best_metrics = None
                    for model_name, metrics in result['metrics'].items():
                        rmse = metrics.get("RMSE")
                        if rmse is not None and rmse < best_rmse:
                            best_rmse = rmse
                            best_model = model_name
                            best_metrics = metrics
                    if best_metrics is not None:
                        y_valid_true = best_metrics.get("y_valid_true")
                        y_valid_pred = best_metrics.get("y_valid_pred")
                        if y_valid_true is not None and y_valid_pred is not None:
                            all_valid_true.append(y_valid_true)
                            all_valid_pred.append(y_valid_pred)
                continue  # ì•„ë˜ ì¼ë°˜ ì²˜ë¦¬ ê±´ë„ˆëœ€

            # ë‚˜ë¨¸ì§€ í´ëŸ¬ìŠ¤í„°(í˜¹ì€ cluster2 ì „ì²´ í•™ìŠµ)
            train_cluster = train_df[train_df['cluster_id'] == cluster_id].copy()
            test_cluster = test_df[test_df['cluster_id'] == cluster_id].copy()

            if len(train_cluster) == 0:
                self.logger.warning(f"í´ëŸ¬ìŠ¤í„° {cluster_id}ì— í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            cluster_trainer = ClusterTrainer(self.config, cluster_id, self.experiment_id)
            result = cluster_trainer.train_and_predict(train_cluster, test_cluster, predict=predict)

            if result.get('predictions') is not None:
                self.cluster_results[cluster_id] = result['predictions']
            self.cluster_metrics[cluster_id] = result['metrics']

            self.logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_id} ì™„ë£Œ")

            # ë² ìŠ¤íŠ¸ ëª¨ë¸ì˜ ê²€ì¦ ì˜ˆì¸¡ê°’ ì§‘ê³„
            best_model = None
            best_rmse = float('inf')
            best_metrics = None
            for model_name, metrics in result['metrics'].items():
                rmse = metrics.get("RMSE")
                if rmse is not None and rmse < best_rmse:
                    best_rmse = rmse
                    best_model = model_name
                    best_metrics = metrics
            if best_metrics is not None:
                y_valid_true = best_metrics.get("y_valid_true")
                y_valid_pred = best_metrics.get("y_valid_pred")
                if y_valid_true is not None and y_valid_pred is not None:
                    all_valid_true.append(y_valid_true)
                    all_valid_pred.append(y_valid_pred)

        # ì „ì²´(ê¸€ë¡œë²Œ) í‰ê°€ì§€í‘œ ê³„ì‚°
        self.global_metrics = None
        if all_valid_true and all_valid_pred:
            y_true_all = np.concatenate(all_valid_true)
            y_pred_all = np.concatenate(all_valid_pred)
            evaluator = ModelEvaluator(self.config)
            self.global_metrics = evaluator.evaluate(y_true_all, y_pred_all)
            self.logger.info("====== ì „ì²´(ê¸€ë¡œë²Œ) ê²€ì¦ í‰ê°€ì§€í‘œ (í´ëŸ¬ìŠ¤í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ê¸°ì¤€) ======")
            for metric, value in self.global_metrics.items():
                if value is not None:
                    self.logger.info(f"  {metric}: {value:.4f}")


    def _save_results_and_report(self) -> None:
        """ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜"""
        self.logger.info("ğŸ’¾ ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        # ë©”íŠ¸ë¦­ ì €ì¥
        self.file_manager.save_metrics(self.cluster_metrics, self.experiment_id)
        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (global_metricsê¹Œì§€ ì „ë‹¬)
        evaluator = ModelEvaluator(self.config)
        evaluator.generate_report(self.cluster_metrics, self.experiment_id, global_metrics=getattr(self, "global_metrics", None))

    def _generate_submission(self, submission_df: pd.DataFrame) -> str:
        """í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì œì¶œ íŒŒì¼ ìƒì„±"""
        if not self.cluster_results:
            self.logger.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ì–´ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        self.logger.info("ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
        # í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ê²°ê³¼ í†µí•©
        all_predictions = []
        for cluster_id, predictions in self.cluster_results.items():
            all_predictions.append(predictions)
        final_predictions = pd.concat(all_predictions, ignore_index=True)
        final_predictions = final_predictions.sort_values('id')
        # ì œì¶œìš© ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
        submission_df = submission_df.drop(columns=[self.config.data.target_column], errors="ignore")
        submission_df = submission_df.merge(final_predictions[['id', self.config.data.target_column]],
                                            on='id', how='left')
        # íŒŒì¼ ì €ì¥
        submission_file = self.file_manager.save_submission(submission_df, self.experiment_id)
        self.logger.info(f"ğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥: {submission_file}")
        return submission_file

    def tune(self, selected_clusters: List[int] = None):
        """í´ëŸ¬ìŠ¤í„°ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ë§Œ ìˆ˜í–‰"""
        self.logger.info(f"ğŸ› ï¸ íŠœë‹ ì‹œì‘: {self.experiment_id}")
        train_df, test_df, _ = self._load_data()
        train_df, test_df = self._add_cluster_ids(train_df, test_df)
        if selected_clusters is None:
            selected_clusters = list(self.config.cluster.mapping.keys())
        for cluster_id in selected_clusters:
            self.logger.info(f"í´ëŸ¬ìŠ¤í„° {cluster_id} íŠœë‹ ì‹œì‘")
            train_cluster = train_df[train_df['cluster_id'] == cluster_id].copy()
            if len(train_cluster) == 0:
                self.logger.warning(f"í´ëŸ¬ìŠ¤í„° {cluster_id}ì— í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            cluster_trainer = ClusterTrainer(self.config, cluster_id, self.experiment_id)
            best_params = cluster_trainer.tune(train_cluster)
            self.logger.info(f"í´ëŸ¬ìŠ¤í„° {cluster_id} íŠœë‹ ê²°ê³¼: {best_params}")
        self.logger.info("âœ… ëª¨ë“  í´ëŸ¬ìŠ¤í„° íŠœë‹ ì™„ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜: ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹± ë° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description="í´ëŸ¬ìŠ¤í„°ë³„ ML íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--config", type=str, default="config/config.yaml",
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--clusters", nargs="*", type=int,
                       help="í•™ìŠµí•  í´ëŸ¬ìŠ¤í„° ID (ê¸°ë³¸ê°’: ëª¨ë“  í´ëŸ¬ìŠ¤í„°)")
    parser.add_argument(
        "--cluster2-mode",
        choices=["split", "all"],
        default="split",
        help="cluster 2 í•™ìŠµ ë°©ì‹: split(ì—¬ë¦„/ë¹„ì—¬ë¦„ ë¶„ë¦¬, ê¸°ë³¸ê°’) ë˜ëŠ” all(ì „ì²´ í•™ìŠµ)"
    )
    parser.add_argument("--models", nargs="+", help="í•™ìŠµí•  ëª¨ë¸ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: --models LGBM XGB)")
    parser.add_argument("--predict", action="store_true", help="ìµœì¢… ì˜ˆì¸¡(ì œì¶œ)ê¹Œì§€ ì‹¤í–‰")
    parser.add_argument("--tune", action="store_true", help="í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ë§Œ ì‹¤í–‰")
    args = parser.parse_args()
    # íŒŒì´í”„ë¼ì¸ ê°ì²´ ìƒì„± ë° ì˜µì…˜ ë°˜ì˜
    pipeline = ClusterMLPipeline(args.config)
    pipeline.cluster2_mode = args.cluster2_mode
    if args.models:
        pipeline.config.training.models = args.models
    # íŠœë‹ë§Œ ìˆ˜í–‰
    if args.tune:
        pipeline.tune(selected_clusters=args.clusters)
    # í•™ìŠµ/ì˜ˆì¸¡ ì‹¤í–‰
    results = pipeline.run(selected_clusters=args.clusters, predict=args.predict)
    print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ! ID: {results['experiment_id']}")

if __name__ == "__main__":
    main()
