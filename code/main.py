# main.py
import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import yaml
import logging
from typing import Dict, List, Tuple, Any

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from src.data.data_loader import DataLoader
from src.data.preprocessor import DataPreprocessor
from src.models.model_factory import ModelFactory
from src.training.trainer import ClusterTrainer
from src.evaluation.evaluator import ModelEvaluator
from src.utils.logger import setup_logging
from src.utils.config import Config
from src.utils.file_manager import FileManager

class ClusterMLPipeline:
    """í´ëŸ¬ìŠ¤í„°ë³„ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self, config_path: str = "config/config.yaml"):
        # ì„¤ì • ë° ê°ì¢… ìœ í‹¸ ê°ì²´ ì´ˆê¸°í™”
        self.config = Config(config_path)
        self.logger = setup_logging(self.config)
        self.file_manager = FileManager(self.config)
        self.experiment_id = self._generate_experiment_id()
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.cluster_results = {}
        self.cluster_metrics = {}
        
        # ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥ (í´ëŸ¬ìŠ¤í„°ë³„ ê³µìœ )
        self.preprocessors = {}

    def _generate_experiment_id(self) -> str:
        """ì‹¤í—˜ ID ìƒì„± (ì‹¤í—˜ëª…_ë‚ ì§œì‹œê°„)"""
        timestamp = datetime.now().strftime("%m%d_%H%M%S")
        return f"{self.config.experiment.name}_{timestamp}"

    def run(self, selected_clusters: List[int] = None, predict: bool = False) -> Dict[str, Any]:
        """íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰ í•¨ìˆ˜"""
        self.logger.info(f"ğŸš€ ì‹¤í—˜ ì‹œì‘: {self.experiment_id}")
        try:
            # ë°ì´í„° ë¡œë”©
            train_df, test_df, submission_df = self._load_data()
            print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {len(train_df)}, í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_df)}")
            
            
            # branch_id â†’ cluster_id ë§¤í•‘ ë° month ì»¬ëŸ¼ ìƒì„±
            train_df, test_df = self._add_cluster_ids(train_df, test_df)
            
            # í´ëŸ¬ìŠ¤í„° ë¯¸ì§€ì • ì‹œ ì „ì²´ ì‚¬ìš©
            if selected_clusters is None:
                selected_clusters = list(self.config.cluster.mapping.keys())
            
            # í´ëŸ¬ìŠ¤í„°ë³„ í•™ìŠµ/ì˜ˆì¸¡
            self._train_clusters(train_df, test_df, selected_clusters, predict=predict)
            
            submission_file = None
            # ì˜ˆì¸¡ ëª¨ë“œë©´ ì œì¶œ íŒŒì¼ ìƒì„±
            if predict:
                submission_file = self._generate_submission(submission_df)
            
            # ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„±
            self._save_results_and_report()
            self.logger.info("âœ… ì‹¤í—˜ ì™„ë£Œ!")
            
            return {
                'experiment_id': self.experiment_id,
                'cluster_metrics': self.cluster_metrics,
                'submission_file': submission_file
            }
        except Exception as e:
            self.logger.error(f"âŒ ì‹¤í—˜ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise

    def _load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """ë°ì´í„° ë¡œë”© í•¨ìˆ˜"""
        self.logger.info("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
        data_loader = DataLoader(self.config)
        return data_loader.load()

    def _add_cluster_ids(self, train_df: pd.DataFrame, test_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """branch_idë¥¼ cluster_idë¡œ ë§¤í•‘í•˜ì—¬ ì»¬ëŸ¼ ì¶”ê°€ ë° month ì»¬ëŸ¼ ìƒì„±"""
        self.logger.info("ğŸ·ï¸ í´ëŸ¬ìŠ¤í„° ID ë§¤í•‘ ì¤‘...")
        
        # branch_id â†’ cluster_id ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        branch_to_cluster = {}
        for cluster_id, branches in self.config.cluster.mapping.items():
            for branch in branches:
                branch_to_cluster[branch] = cluster_id
        
        # ë§¤í•‘ ì ìš©
        train_df['cluster_id'] = train_df['branch_id'].map(branch_to_cluster)
        test_df['cluster_id'] = test_df['branch_id'].map(branch_to_cluster)
        
        # month ì»¬ëŸ¼ ìƒì„± (ë°ì´í„° íƒ€ì… ì²˜ë¦¬ ê°œì„ )
        try:
            train_df['month'] = pd.to_datetime(train_df['tm'], errors='coerce', format='%Y%m%d%H').dt.month
            test_df['month'] = pd.to_datetime(test_df['tm'], errors='coerce', format='%Y%m%d%H').dt.month
            
            # NaN ê°’ì„ -1ë¡œ ì±„ìš°ê³  ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
            train_df['month'] = train_df['month'].fillna(-1).astype(int)
            test_df['month'] = test_df['month'].fillna(-1).astype(int)
            
        except KeyError as e:
            self.logger.error(f"ë‚ ì§œ(tm) ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
            raise   
        
        # ë§¤í•‘ë˜ì§€ ì•Šì€ ë°ì´í„° í™•ì¸
        unmapped_train = train_df[train_df['cluster_id'].isna()]
        unmapped_test = test_df[test_df['cluster_id'].isna()]
        if len(unmapped_train) > 0 or len(unmapped_test) > 0:
            self.logger.warning(f"ë§¤í•‘ë˜ì§€ ì•Šì€ ë°ì´í„°: train {len(unmapped_train)}, test {len(unmapped_test)}")
        
        return train_df, test_df

    def _prepare_cluster2_data(self, train_df: pd.DataFrame, test_df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """Cluster 2 ë°ì´í„°ë¥¼ summer/restë¡œ ë¶„í• """
        self.logger.info("ğŸ”„ Cluster 2 ë°ì´í„° ë¶„í•  ì¤‘...")
        
        # Cluster 2 ë°ì´í„° í•„í„°ë§
        train_cluster2 = train_df[train_df['cluster_id'] == 2].copy()
        test_cluster2 = test_df[test_df['cluster_id'] == 2].copy()
        
        # ì›”ë³„ ë°ì´í„° ê°œìˆ˜ í™•ì¸
        self.logger.info(f"Cluster 2 ì›”ë³„ ë¶„í¬:\n{train_cluster2['month'].value_counts().sort_index()}")
        
        # ì—¬ë¦„(6~9ì›”)ê³¼ ë‚˜ë¨¸ì§€ ë¶„í• 
        summer_months = [6, 7, 8, 9]
        
        train_summer = train_cluster2[train_cluster2['month'].isin(summer_months)].copy()
        train_rest = train_cluster2[~train_cluster2['month'].isin(summer_months)].copy()
        test_summer = test_cluster2[test_cluster2['month'].isin(summer_months)].copy()
        test_rest = test_cluster2[~test_cluster2['month'].isin(summer_months)].copy()
        
        self.logger.info(f"Cluster 2 ë¶„í•  ê²°ê³¼: ì—¬ë¦„ {len(train_summer)}ê°œ, ë‚˜ë¨¸ì§€ {len(train_rest)}ê°œ")
        
        return {
            'train_summer': train_summer,
            'train_rest': train_rest,
            'test_summer': test_summer,
            'test_rest': test_rest
        }

    # def _preprocess_cluster_data(self, cluster_id: str, train_data: pd.DataFrame, test_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    #     """í´ëŸ¬ìŠ¤í„°ë³„ ë°ì´í„° ì „ì²˜ë¦¬ (fit_transform â†’ transform)"""
    #     self.logger.info(f"ğŸ”§ Cluster {cluster_id} ì „ì²˜ë¦¬ ì‹œì‘")
        
    #     # ì „ì²˜ë¦¬ ê°ì²´ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    #     if cluster_id not in self.preprocessors:
    #         self.preprocessors[cluster_id] = DataPreprocessor(self.config)
        
    #     preprocessor = self.preprocessors[cluster_id]
        
    #     # í•™ìŠµ ë°ì´í„°ë¡œ fit_transform
    #     train_processed = preprocessor.fit_transform(train_data)
        
    #     # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” transformë§Œ
    #     test_processed = preprocessor.transform(test_data)
        
    #     self.logger.info(f"âœ… Cluster {cluster_id} ì „ì²˜ë¦¬ ì™„ë£Œ: train {train_processed.shape}, test {test_processed.shape}")
        
    #     return train_processed, test_processed

    def _train_single_cluster(self, cluster_id: str, train_data: pd.DataFrame, test_data: pd.DataFrame, predict: bool = False) -> Dict[str, Any]:
        """ë‹¨ì¼ í´ëŸ¬ìŠ¤í„°/ì„œë¸Œê·¸ë£¹ í•™ìŠµ"""
        if len(train_data) == 0:
            self.logger.warning(f"Cluster {cluster_id}ì— í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            return {'predictions': None, 'metrics': {}}
        
        # # ì „ì²˜ë¦¬ ìˆ˜í–‰
        # train_processed, test_processed = self._preprocess_cluster_data(cluster_id, train_data, test_data)
        
        # ëª¨ë¸ í•™ìŠµ
        cluster_trainer = ClusterTrainer(self.config, cluster_id, self.experiment_id)
        result = cluster_trainer.train_and_predict(train_data, test_data, predict=predict)
        
        return result

    def _train_clusters(
        self,
        train_df: pd.DataFrame,
        test_df: pd.DataFrame,
        selected_clusters: List[int],
        predict=False
    ) -> None:
        self.logger.info(f"ğŸ¯ ì„ íƒëœ í´ëŸ¬ìŠ¤í„°: {selected_clusters}")

        all_valid_true = []
        all_valid_pred = []

        for cluster_id in selected_clusters:
            self.logger.info(f"{'='*20} í´ëŸ¬ìŠ¤í„° {cluster_id} ì²˜ë¦¬ ì‹œì‘ {'='*20}")

            # Cluster 2ë§Œ íŠ¹ë³„ ì²˜ë¦¬
            if (str(cluster_id) == "2" and 
                hasattr(self, "cluster2_mode") and 
                self.cluster2_mode == "split"):
                
                # Cluster 2 ë°ì´í„° ë¶„í• 
                cluster2_data = self._prepare_cluster2_data(train_df, test_df)
                
                # Summer ê·¸ë£¹ í•™ìŠµ
                if len(cluster2_data['train_summer']) > 0:
                    self.logger.info("ğŸŒ Cluster 2_summer (6~9ì›”) í•™ìŠµ")
                    result = self._train_single_cluster(
                        "2_summer", 
                        cluster2_data['train_summer'], 
                        cluster2_data['test_summer'], 
                        predict=predict
                    )
                    
                    if result.get('predictions') is not None:
                        self.cluster_results["2_summer"] = result['predictions']
                    self.cluster_metrics["2_summer"] = result['metrics']
                    
                    # ê²€ì¦ ê²°ê³¼ ì§‘ê³„
                    self._collect_validation_results(result, all_valid_true, all_valid_pred)

                # Rest ê·¸ë£¹ í•™ìŠµ
                if len(cluster2_data['train_rest']) > 0:
                    self.logger.info("â„ï¸ Cluster 2_rest (1~5,10~12ì›”) í•™ìŠµ")
                    result = self._train_single_cluster(
                        "2_rest", 
                        cluster2_data['train_rest'], 
                        cluster2_data['test_rest'], 
                        predict=predict
                    )
                    
                    if result.get('predictions') is not None:
                        self.cluster_results["2_rest"] = result['predictions']
                    self.cluster_metrics["2_rest"] = result['metrics']
                    
                    # ê²€ì¦ ê²°ê³¼ ì§‘ê³„
                    self._collect_validation_results(result, all_valid_true, all_valid_pred)
                
                continue  # ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„° ì²˜ë¦¬ë¡œ ë„˜ì–´ê°

            # ë‚˜ë¨¸ì§€ í´ëŸ¬ìŠ¤í„° ì¼ë°˜ ì²˜ë¦¬
            train_cluster = train_df[train_df['cluster_id'] == cluster_id].copy()
            test_cluster = test_df[test_df['cluster_id'] == cluster_id].copy()
            print(f"í´ëŸ¬ìŠ¤í„° {cluster_id} í•™ìŠµ ë°ì´í„° í¬ê¸°: {len(train_cluster)}")
            print(f"í´ëŸ¬ìŠ¤í„° {cluster_id} í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_cluster)}")

            result = self._train_single_cluster(str(cluster_id), train_cluster, test_cluster, predict=predict)
            
            if result.get('predictions') is not None:
                self.cluster_results[cluster_id] = result['predictions']
            self.cluster_metrics[cluster_id] = result['metrics']

            self.logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_id} ì™„ë£Œ")
            
            # ê²€ì¦ ê²°ê³¼ ì§‘ê³„
            self._collect_validation_results(result, all_valid_true, all_valid_pred)

        # ì „ì²´(ê¸€ë¡œë²Œ) í‰ê°€ì§€í‘œ ê³„ì‚°
        self._calculate_global_metrics(all_valid_true, all_valid_pred)

    def _collect_validation_results(self, result: Dict[str, Any], all_valid_true: List, all_valid_pred: List) -> None:
        """ê²€ì¦ ê²°ê³¼ ìˆ˜ì§‘"""
        best_model = None
        best_rmse = float('inf')
        best_metrics = None
        
        for model_name, metrics in result['metrics'].items():
            rmse = metrics.get("RMSE")
            if rmse is not None and rmse < best_rmse:
                best_rmse = rmse
                best_model = model_name
                best_metrics = metrics
        
        if best_metrics is not None:
            y_valid_true = best_metrics.get("y_valid_true")
            y_valid_pred = best_metrics.get("y_valid_pred")
            if y_valid_true is not None and y_valid_pred is not None:
                all_valid_true.append(y_valid_true)
                all_valid_pred.append(y_valid_pred)

    def _calculate_global_metrics(self, all_valid_true: List, all_valid_pred: List) -> None:
        """ì „ì²´ í‰ê°€ì§€í‘œ ê³„ì‚°"""
        self.global_metrics = None
        if all_valid_true and all_valid_pred:
            y_true_all = np.concatenate(all_valid_true)
            y_pred_all = np.concatenate(all_valid_pred)
            evaluator = ModelEvaluator(self.config)
            self.global_metrics = evaluator.evaluate(y_true_all, y_pred_all)
            
            self.logger.info("====== ì „ì²´(ê¸€ë¡œë²Œ) ê²€ì¦ í‰ê°€ì§€í‘œ (í´ëŸ¬ìŠ¤í„°ë³„ ë² ìŠ¤íŠ¸ ëª¨ë¸ ê¸°ì¤€) ======")
            for metric, value in self.global_metrics.items():
                if value is not None:
                    self.logger.info(f"  {metric}: {value:.4f}")

    def _save_results_and_report(self) -> None:
        """ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜"""
        self.logger.info("ğŸ’¾ ê²°ê³¼ ì €ì¥ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        # ë©”íŠ¸ë¦­ ì €ì¥
        self.file_manager.save_metrics(self.cluster_metrics, self.experiment_id)
        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        evaluator = ModelEvaluator(self.config)
        evaluator.generate_report(
            self.cluster_metrics, 
            self.experiment_id, 
            global_metrics=getattr(self, "global_metrics", None)
        )

    def _generate_submission(self, submission_df: pd.DataFrame) -> str:
        """í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ì œì¶œ íŒŒì¼ ìƒì„±"""
        if not self.cluster_results:
            self.logger.warning("ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ì–´ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        self.logger.info("ğŸ“ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
        
        # í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ê²°ê³¼ í†µí•©
        all_predictions = []
        for cluster_id, predictions in self.cluster_results.items():
            all_predictions.append(predictions)
        
        final_predictions = pd.concat(all_predictions, ignore_index=True)
        final_predictions = final_predictions.sort_values('id')
        
        # ì œì¶œìš© ë°ì´í„°í”„ë ˆì„ê³¼ ë³‘í•©
        submission_df = submission_df.drop(columns=[self.config.data.target_column], errors="ignore")
        submission_df = submission_df.merge(
            final_predictions[['id', self.config.data.target_column]],
            on='id', how='left'
        )
        
        # íŒŒì¼ ì €ì¥
        submission_file = self.file_manager.save_submission(submission_df, self.experiment_id)
        self.logger.info(f"ğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥: {submission_file}")
        return submission_file

    def tune(self, selected_clusters: List[int] = None):
        """í´ëŸ¬ìŠ¤í„°ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ë§Œ ìˆ˜í–‰"""
        self.logger.info(f"ğŸ› ï¸ íŠœë‹ ì‹œì‘: {self.experiment_id}")
        train_df, test_df, _ = self._load_data()
        train_df, test_df = self._add_cluster_ids(train_df, test_df)
        
        if selected_clusters is None:
            selected_clusters = list(self.config.cluster.mapping.keys())
        
        for cluster_id in selected_clusters:
            self.logger.info(f"í´ëŸ¬ìŠ¤í„° {cluster_id} íŠœë‹ ì‹œì‘")
            train_cluster = train_df[train_df['cluster_id'] == cluster_id].copy()
            
            if len(train_cluster) == 0:
                self.logger.warning(f"í´ëŸ¬ìŠ¤í„° {cluster_id}ì— í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            cluster_trainer = ClusterTrainer(self.config, cluster_id, self.experiment_id)
            # 1. ì „ì²˜ë¦¬ê¸° fit ë¨¼ì € ìˆ˜í–‰ (train_clusterëŠ” ì›ë³¸ ë°ì´í„°)
            cluster_trainer.preprocessor.fit_transform(train_cluster)

            # 2. ì´í›„ tuneì—ì„œëŠ” transformë§Œ í•˜ë„ë¡ ë³€ê²½ëœ tune í•¨ìˆ˜ í˜¸ì¶œ
            best_params = cluster_trainer.tune(train_cluster)
            self.logger.info(f"í´ëŸ¬ìŠ¤í„° {cluster_id} íŠœë‹ ê²°ê³¼: {best_params}")
        
        self.logger.info("âœ… ëª¨ë“  í´ëŸ¬ìŠ¤í„° íŠœë‹ ì™„ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜: ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹± ë° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description="í´ëŸ¬ìŠ¤í„°ë³„ ML íŒŒì´í”„ë¼ì¸")
    parser.add_argument("--config", type=str, default="config/config.yaml",
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--clusters", nargs="*", type=int,
                       help="í•™ìŠµí•  í´ëŸ¬ìŠ¤í„° ID (ê¸°ë³¸ê°’: ëª¨ë“  í´ëŸ¬ìŠ¤í„°)")
    parser.add_argument(
        "--cluster2-mode",
        choices=["split", "all"],
        default="split",
        help="cluster 2 í•™ìŠµ ë°©ì‹: split(ì—¬ë¦„/ë¹„ì—¬ë¦„ ë¶„ë¦¬, ê¸°ë³¸ê°’) ë˜ëŠ” all(ì „ì²´ í•™ìŠµ)"
    )
    parser.add_argument("--models", nargs="+", help="í•™ìŠµí•  ëª¨ë¸ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: --models LGBM XGB)")
    parser.add_argument("--predict", action="store_true", help="ìµœì¢… ì˜ˆì¸¡(ì œì¶œ)ê¹Œì§€ ì‹¤í–‰")
    parser.add_argument("--tune", action="store_true", help="í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ë§Œ ì‹¤í–‰")
    
    args = parser.parse_args()
    
    # íŒŒì´í”„ë¼ì¸ ê°ì²´ ìƒì„± ë° ì˜µì…˜ ë°˜ì˜
    pipeline = ClusterMLPipeline(args.config)
    pipeline.cluster2_mode = args.cluster2_mode
    
    if args.models:
        pipeline.config.training.models = args.models
    
    # íŠœë‹ë§Œ ìˆ˜í–‰
    if args.tune:
        pipeline.tune(selected_clusters=args.clusters)
        return
    
    # í•™ìŠµ/ì˜ˆì¸¡ ì‹¤í–‰
    results = pipeline.run(selected_clusters=args.clusters, predict=args.predict)
    print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ! ID: {results['experiment_id']}")

if __name__ == "__main__":
    main()